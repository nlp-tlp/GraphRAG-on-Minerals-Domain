### Requirements

Python 3.10-3.12

### Environment Setup

1. Create a virtual environment:
   ```bash
   python -m venv venv
   ```

2. Activate a virtual environment:
  - **macOS/Linux:**  
    ```bash
    source venv/bin/activate
    ```
  - **Windows (Command Prompt):**  
    ```cmd
    venv\Scripts\activate
    ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Copy the contents of `.env.example` to a new file in the same folder named `.env`. Add your OpenAI API key (to use `gpt-4o-mini`) to the `.env` file by setting `api_key = <your_key>`.

### GraphRAG Indexing

> Note: This process may take hours and can be expensive depending on the size of the input and LLM used. 

1. In each of the four schema directories, copy the contents of `.env.example` to a new file in the same folder named `.env`. `.env` contains `GRAPHRAG_API_KEY=<API_KEY>` which should be replaced by your own OpenAI API key.

2. Run indexing pipeline using Minerals Domain Schema:
   ```bash
   python -m graphrag.index --root ./minerals_domain_schema
   ```
   Run indexing pipeline using Expanded Minerals Domain Schema:
   ```bash
   python -m graphrag.index --root ./expanded_minerals_domain_schema
   ```
   Run indexing pipeline using Auto-Generated Schema:
   ```bash
   python -m graphrag.index --root ./auto_generated_schema
   ```
   Run indexing pipeline using Schema-less pipeline:
   ```bash
   python -m graphrag.index --root ./schema_less
   ```

### GraphRAG Query

Running the following scripts will allow you to select which schema's index to query. By default, all 15 MRIWA competency questions are asked and results are saved to a .csv file.

- To run **local search**:
  ```bash
  python local_search.py
  ```

- To run **global search**:
  ```bash
  python global_search.py
  ```

### Additional Notes

- `local_search.py` and `global_search.py` are adapted from [Microsoft's GraphRAG Notebooks](https://microsoft.github.io/graphrag/query/notebooks/overview/)
- Each of the four schema directories and their contents are generated using [Microsoft's GraphRAG](https://github.com/microsoft/graphrag) framework. The content we alter/provide include:
   - MRIWA reports in `/input` for all pipelines.
   - `model` in `settings.yaml` for all pipelines to `gpt-4o-mini`.
   - `entity_types` in `settings.yaml` for both the [Minerals Domain Schema Pipeline](https://github.com/nlp-tlp/GraphRAG-on-Minerals-Domain/tree/main/src/minerals_domain_schema) and the [Expanded Minerals Domain Schema Pipeline](https://github.com/nlp-tlp/GraphRAG-on-Minerals-Domain/tree/main/src/expanded_minerals_domain_schema), where we use our original minerals-domain schemas.
   - `entity types` in `settings.yaml` for the [Auto-Generated Schema Pipeline](https://github.com/nlp-tlp/GraphRAG-on-Minerals-Domain/tree/main/src/auto_generated_schema), where the schema was pre-generated by [GraphRAG's Prompt Tuner](https://microsoft.github.io/graphrag/prompt_tuning/overview/).
   - [Entity Extraction Prompt](https://github.com/nlp-tlp/GraphRAG-on-Minerals-Domain/blob/main/src/schema_less/prompts/entity_extraction.txt) for the [Schema-less Pipeline](https://github.com/nlp-tlp/GraphRAG-on-Minerals-Domain/tree/main/src/schema_less), where we alter the prompt to instead “identify all entities needed from the text in order to capture the information and ideas in the text”.
- The default GraphRAG entity extraction prompt used during Indexing includes default few-shot examples to enable in-context learning. However, these few-shot examples are not specific to the minerals domain. The Microsoft GraphRAG paper suggests using domain-specific examples could improve GraphRAG's performance, particularly in fields requiring specialised knowledge, such as science.

